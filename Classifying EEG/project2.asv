%% load data
clear all; 
clc;
close all;
T = load("CI_Project_data_01.mat");
tData = T.TrainData;
tLabel = T.TrainLabel;
%% create and normalize feature vector
for i=1:110
    NewSig = tData(:,:,i);
    for j = 1 : 30
        [Train_Features(j,i),Train_Features(2*j,i)] = max(abs(NewSig(j,:))) ;
    end
    for j = 1 : 30
        Train_Features(j+60,i) = var(NewSig(j,:)) ;
    end
    for j = 1 : 30
        Train_Features(j+90,i) = mean(NewSig(j,:)) ;
    end
    for j = 1:30
        for k = j + 1:30
            Train_Features((j-1)*30 - j*(j+1)/2+k+120-j,i) = corr(NewSig(j,:)',NewSig(k,:)') ;
        end
    end
%     for j = 1 :30
%         psdnew = PSD(tData(j, 1:512, i))';
%         [~,I] = max(psdnew(:, 1:3),[],2);
%         freq = I;
%         Train_Features(526+j, i) = freq;
%         [~,I] = max(psdnew(:, 4:7),[],2);
%         freq = I + 3;
%         Train_Features(526+j+30, i) = freq;
%         [~,I] = max(psdnew(:, 8:12),[],2);
%         freq = I + 7;
%         Train_Features(526+j+60, i) = freq;
%         [~,I] = max(psdnew(:, 13:16),[],2);
%         freq = I + 12;
%         Train_Features(526+j+90, i) = freq;
%         [~,I] = max(psdnew(:, 17:20),[],2);
%         freq = I + 16;
%         Train_Features(526+j+120, i) = freq;
%         [~,I] = max(psdnew(:, 21:30),[],2);
%         freq = I + 20;
%         Train_Features(526+j+150, i) = freq;
%         [~,I] = max(psdnew(:, 31:50),[],2);
%         freq = I + 30;
%         Train_Features(526+j+180, i) = freq;
%     end
for j = 1:30
psdnew = PSD(tData(j, 1:512, i))';
        Train_Features(526+j, i) = mean(psdnew(:, 1:3),2);
        Train_Features(526+j+30, i) = mean(psdnew(:, 4:7),2);
        Train_Features(526+j+60, i) = mean(psdnew(:, 8:12),2);
        Train_Features(526+j+90, i) = mean(psdnew(:, 13:16),2);
        Train_Features(526+j+120, i) = mean(psdnew(:, 17:20),2);
        Train_Features(526+j+150, i) = mean(psdnew(:, 21:30),2);
        Train_Features(526+j+180, i) = mean(psdnew(:, 31:50),2);
end
end
[Normalized_Train_Features,xPS] = mapminmax(Train_Features) ;
%%  Parameter setting
% Set 25% data as validation set
ho = 0.25; 
% Hold-out method
HO = cvpartition(tLabel','HoldOut',ho);
N        = 10;
max_Iter = 70;
c1       = 2;     % cognitive factor
c2       = 2;     % social factor
w        = 1;     % inertia weight
% Particle Swarm Optimization
lab = tLabel' - ones(110,1);
[sFeat,Sf,Nf,curve] = jPSO(Train_Features',lab,N,max_Iter,c1,c2,w,HO);
[sFeat1,Sf1,Nf,curve] = jPSO(sFeat,lab,N,max_Iter,c1,c2,w,HO);
[sFeat2,Sf2,Nf,curve] = jPSO(sFeat1,lab,N,max_Iter,c1,c2,w,HO);
[sFeat3,Sf3,Nf,curve] = jPSO(sFeat2,lab,N,max_Iter,c1,c2,w,HO);
%%
Train_Label = tLabel - ones(1,110);
s = sFeat3';
for N=5:3:26
    ACC = 0 ;
    % 5-fold cross-validation
    for k=1:5
        train_indices = [1:(k-1)*21,k*21+1:110] ;
        valid_indices = (k-1)*21+1:k*21 ;
        TrainX = s(:,train_indices) ; % Extracting best features:l
        ValX = s(:,valid_indices) ; % Extracting best features: l
        TrainY = Train_Label(train_indices) ;
        ValY = Train_Label(valid_indices) ;
        net = patternnet(N);
        net = train(net,TrainX,TrainY);
        predict_ys = net(ValX);
        Thr = 0.5 ;
        predict_y = predict_ys >= Thr ;
        ACC = ACC + length(find(predict_y==ValY)) ;
    end

    ACCMatnew1((N-2)/3) = ACC/110 ;
end
ACCMatnew1
%% test
Train_Label = tLabel - ones(1,110);
s = sFeat3';
N = 14;
TrainX = s(:,1:110);
TrainY = Train_Label(1:110) ;
net = patternnet(N);
net = train(net,TrainX,TrainY);
u = T.TestData;
clear Normalized_Train_Features
clear Train_Features
for i=1:50
    NewSig = u(:,:,i);
    for j = 1 : 30
        [Train_Features(j,i),Train_Features(2*j,i)] = max(abs(NewSig(j,:))) ;
    end
    for j = 1 : 30
        Train_Features(j+60,i) = var(NewSig(j,:)) ;
    end
    for j = 1 : 30
        Train_Features(j+90,i) = mean(NewSig(j,:)) ;
    end
    for j = 1:30
        for k = j + 1:30
            Train_Features((j-1)*30 - j*(j+1)/2+k+120-j,i) = corr(NewSig(j,:)',NewSig(k,:)') ;
        end
    end
for j = 1:30
psdnew = PSD(tData(j, 1:512, i))';
        Train_Features(526+j, i) = mean(psdnew(:, 1:3),2);
        Train_Features(526+j+30, i) = mean(psdnew(:, 4:7),2);
        Train_Features(526+j+60, i) = mean(psdnew(:, 8:12),2);
        Train_Features(526+j+90, i) = mean(psdnew(:, 13:16),2);
        Train_Features(526+j+120, i) = mean(psdnew(:, 17:20),2);
        Train_Features(526+j+150, i) = mean(psdnew(:, 21:30),2);
        Train_Features(526+j+180, i) = mean(psdnew(:, 31:50),2);
end
end
[Normalized_Train_Features,xPS] = mapminmax(Train_Features) ;

ValX = Normalized_Train_Features(:,:) ;
predict_ys = net(ValX);
Thr = 0.5 ;
predict_y = predict_ys >= Thr;
predict_y = predict_y + ones();






%% RBF

spreadMat = 0.5:0.5:7 ;
NMat = 5:5:45 ;
for sp = 1:14
    spread = spreadMat(sp) ;
    for n = 1:9
        Maxnumber = NMat(n) ;
        ACC = 0 ;
        % 5-fold cross-validation
        for k=1:5
            train_indices = [1:(k-1)*21,k*21+1:110] ;
            valid_indices = (k-1)*21+1:k*21 ;
            TrainX = s(:,train_indices) ;
            ValX = s(:,valid_indices) ;
            TrainY = Train_Label(train_indices) ;
            ValY = Train_Label(valid_indices) ;
            net = newrb(TrainX,TrainY,10^-5,spread,Maxnumber) ;
            predict_y = net(ValX);
            Thr = 0.5 ;
            predict_y = predict_y >= Thr ;
            ACC = ACC + length(find(predict_y==ValY)) ;
        end
        ACCMat2(sp,n) = ACC/110 ;
    end
end
 [R,C] = ndgrid(1:size(ACCMat2,1),1:size(ACCMat2,2));
 [b,idx] = sort(ACCMat2(:));
 [R(idx),C(idx)]








%% functions
function [sFeat,Sf,Nf,curve]=jPSO(feat,label,N,max_Iter,c1,c2,w,HO)
% Parameters
lb    = -1;
ub    = 1; 
thres = 0.5;
% Objective function
fun = @jFitnessFunction; 
% Number of dimensions
dim = size(feat,2); 
% Initial 
X   = zeros(N,dim);
V   = zeros(N,dim); 
for i = 1:N
  for d = 1:dim
    X(i,d) = lb + (ub - lb) * rand();
  end
end  
% Fitness
fit  = zeros(1,N); 
fitG = inf;
for i = 1:N 
  fit(i) = fun(feat,label,(X(i,:) > thres),HO); 
  % Gbest update
  if fit(i) < fitG
    Xgb  = X(i,:); 
    fitG = fit(i);
  end
end
% PBest
Xpb  = X; 
fitP = fit;
% Pre
curve = inf;
t = 1;  
% Iterations
while t <= max_Iter
  for i = 1:N
    for d = 1:dim
      r1 = rand();
      r2 = rand();
      % Velocity update 
      V(i,d) = w * V(i,d) + c1 * r1 * (Xpb(i,d) - X(i,d)) + ...
        c2 * r2 * (Xgb(d) - X(i,d)); 
      % Position update 
      X(i,d) = X(i,d) + V(i,d);
    end
    % Boundary
    XB = X(i,:); XB(XB > ub) = ub; XB(XB < lb) = lb; 
    X(i,:) = XB;
    % Fitness
    fit(i) = fun(feat,label,(X(i,:) > thres),HO);
    % Pbest update
    if fit(i) < fitP(i)
      Xpb(i,:) = X(i,:); 
      fitP(i)  = fit(i);
    end
    % Gbest update
    if fitP(i) < fitG
      Xgb  = Xpb(i,:);
      fitG = fitP(i);
    end
  end
  curve(t) = fitG;
  fprintf('\nIteration %d GBest (PSO)= %f',t,curve(t))
  t = t + 1;
end
% Select features based on selected index
Pos   = 1:dim;
Sf    = Pos((Xgb > thres) == 1); 
sFeat = feat(:,Sf); 
Nf    = length(Sf);
end
function cost = jFitnessFunction(feat,label,X,HO)
if sum(X == 1) == 0
  cost = 1;
else
  cost = jwrapperKNN(feat(:, X == 1),label,HO);
end
end
function error = jwrapperKNN(sFeat,label,HO)
%---// Parameter setting for k-value of KNN //
k = 5; 
xtrain = sFeat(HO.training == 1,:);
ytrain = label(HO.training == 1); 
xvalid = sFeat(HO.test == 1,:); 
yvalid = label(HO.test == 1); 
Model     = fitcknn(xtrain,ytrain,'NumNeighbors',k); 
pred      = predict(Model,xvalid);
num_valid = length(yvalid); 
correct   = 0;
for i = 1:num_valid
  if isequal(yvalid(i),pred(i))
    correct = correct + 1;
  end
end
Acc   = correct / num_valid; 
error = 1 - Acc;
end
function psd = PSD(x)
fs = 256;
t = 0:1/fs:1-1/fs;
N = length(x);
psd = periodogram(x,rectwin(N),N,fs);
end









